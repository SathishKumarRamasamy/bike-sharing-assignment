{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Reading , understanding and Visualizing the data\n",
    "2. Preparing the data for Modelling\n",
    "    - Train - Test split\n",
    "    - Rescaling\n",
    "3. Training the Model \n",
    "4. Residual Analysis\n",
    "5. Predictions and Evaluations on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading , understanding and Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Needed Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Plot size globally for better visualization\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "bike_sharing = pd.read_csv('day.csv')\n",
    "bike_sharing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing.info()\n",
    "\n",
    "\"\"\"No Missing Values and no datatype conversions required\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Insignificant Columns\n",
    "# instant is unique as it is a record index - it doesn't add any value\n",
    "# casual and registered are already captured in cnt and the target column is cnt, hence dropping casual and registered\n",
    "# dropping dteday as the date doesn't add significance because it is already being consumed in other significant forms like month,weekday,holiday and so on\n",
    "insig_cols = ['instant','dteday','casual','registered']\n",
    "bike_sharing.drop(insig_cols,axis=1,inplace=True)\n",
    "bike_sharing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data for linearity and multi collinearity\n",
    "plt.figure()\n",
    "sns.pairplot(bike_sharing)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"At this point,temp and atemp may be multi collinear (+vely correlated) and is obviously explainable because temp is the actual temperature and atemp is feeling temperatue. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data: Continuous Independent Variables\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.pairplot(data=bike_sharing,x_vars=['temp', 'atemp', 'hum', 'windspeed'],y_vars='cnt')\n",
    "plt.suptitle('Analysis of Numerical Variables against target variable',y=1.1)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"There seems to be linear correlation between temp vs cnt and atemp vs cnt\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data: Categorical Independent Variables\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,4,1)\n",
    "sns.boxplot(x='yr',y='cnt',data=bike_sharing)\n",
    "plt.subplot(2,4,2)\n",
    "sns.boxplot(x='season',y='cnt',data=bike_sharing)\n",
    "plt.subplot(2,4,3)\n",
    "sns.boxplot(x='mnth',y='cnt',data=bike_sharing)\n",
    "plt.subplot(2,4,4)\n",
    "sns.boxplot(x='holiday',y='cnt',data=bike_sharing)\n",
    "plt.subplot(2,4,5)\n",
    "sns.boxplot(x='weekday',y='cnt',data=bike_sharing)\n",
    "plt.subplot(2,4,6)\n",
    "sns.boxplot(x='workingday',y='cnt',data=bike_sharing)\n",
    "plt.subplot(2,4,7)\n",
    "sns.boxplot(x='weathersit',y='cnt',data=bike_sharing)\n",
    "plt.suptitle('Analysis of Categorical Variables against target variable')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferences\n",
    "- year seems to have very good influence of total rental bikes as the entire distribution for 2019 is higher than that of 2018 indicating a pattern\n",
    "- season seems to have influence on number of people opting for total rental bikes thereby months also have influence. People tend to opt for more rental bikes in Summer and Fall \n",
    "- workingday & weekday doesn't seem to influence total rental bikes as the median and distribution is similar. \n",
    "- Weather situation seems to influence on total rental bikes where people opt for more rental bikes in clear or partly cloudy weather  \n",
    "- People tend to opt for little more rental bikes during no holidays than on holidays. The influence could be little less appreciable attributing to the less difference in median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  Preparing the data for Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n",
    " - yes/no variables are already encoded with 1/0. No change needed\n",
    " - Certain Nominal Variables are represented as Ordinal variables like season, month, weekday, weathersit. Those has to be converted and dummy encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Listing Categorical columns and its unique values\n",
    "column_values = {}\n",
    "col_list = ['yr','season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "for row in col_list:\n",
    "    column_values[row] = list(bike_sharing[row].value_counts().index)\n",
    "\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plug in string values from data dict for Nominal Variables which are represented as Ordinal values in the dataset\n",
    "yr_mappings = {0:'2018',1:'2019'}\n",
    "season_mappings = {1:'spring', 2:'summer', 3:'fall', 4:'winter'}\n",
    "weathersit_mappings = {1:'Clear',2:'Mist_Cloudy',3:'Light_Snow',4:'Heavy_Rain'}\n",
    "\n",
    "bike_sharing['yr'] = bike_sharing[['yr']].apply(lambda x : x.map(yr_mappings))\n",
    "bike_sharing['season'] = bike_sharing[['season']].apply(lambda x : x.map(season_mappings))\n",
    "bike_sharing['weathersit'] = bike_sharing[['weathersit']].apply(lambda x : x.map(weathersit_mappings))\n",
    "bike_sharing['mnth'] = bike_sharing['mnth'].apply(lambda x : calendar.month_abbr[x])\n",
    "bike_sharing['weekday'] = bike_sharing['weekday'].apply(lambda x : calendar.day_abbr[x])\n",
    "bike_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy encoding\n",
    "var_list_encoding = ['yr','season','mnth','weekday','weathersit']\n",
    "dummy_encoded_values = pd.get_dummies(data=bike_sharing[var_list_encoding],drop_first=True)\n",
    "\n",
    "# Add the new encoded cols to original dataframe and drop the source columns\n",
    "bike_sharing = pd.concat([bike_sharing,dummy_encoded_values],axis=1)\n",
    "bike_sharing.drop(var_list_encoding,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split test train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(bike_sharing,train_size=0.7,random_state=100)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the features using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the numerical columns other than categorical dummy cols\n",
    "num_vars = ['temp','atemp','hum','windspeed','cnt']\n",
    "scaler = MinMaxScaler()\n",
    "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:  Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing training set to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('cnt')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Linear Regression Model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "# Running RFE with output number of values as 20\n",
    "output_var_count = 20\n",
    "rfe = RFE(lm,n_features_to_select=output_var_count)\n",
    "rfe = rfe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_rfe_cols = X_train.columns[rfe.support_]\n",
    "resulting_rfe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building using stats model to get detailed statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the columns from RFE\n",
    "X_train_rfe = X_train[resulting_rfe_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Constant\n",
    "def add_constant(X_train):\n",
    "    return sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Model and return summary\n",
    "def build_model(X_train,y_train):\n",
    "    lm = sm.OLS(y_train,X_train).fit() # Fitting the model\n",
    "    return lm.summary(),lm # Return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VIF\n",
    "def compute_vif(X_train):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = X_train.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2) # Rounding to 2 decimal values\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "    return vif\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model with 20 params from RFE\n",
    "build_model(add_constant(X_train_rfe),y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing VIF for 15 variables from RFE\n",
    "compute_vif(X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations:\n",
    "- RFE chosen 20 variables is able to explain 84% variance in the target variable (Adjusted R square is 84%)\n",
    "- atemp has high p value and high VIF, Let's start by removing atemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove atemp which has very high p value and high VIF\n",
    "cols_to_be_removed = ['atemp']\n",
    "X_train_rfe_m = X_train_rfe.drop(cols_to_be_removed,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(add_constant(X_train_rfe_m),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_vif(X_train_rfe_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations:\n",
    "- Adjusted R square has remained the same indicating that atemp is a redundant variable\n",
    "- As indicated by EDA, atemp has very high correlation with temp, removing atemp also brought down vif of temp\n",
    "- holiday has high p value although it has low VIF\n",
    "\n",
    "As a rule of thumb, remove the variable with high p value, let's remove holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove atemp which has very high p value and high VIF\n",
    "# Remove holiday as it has high p value\n",
    "cols_to_be_removed = ['atemp','holiday']\n",
    "X_train_rfe_m = X_train_rfe.drop(cols_to_be_removed,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(add_constant(X_train_rfe_m),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_vif(X_train_rfe_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations:\n",
    "- Adjusted R square has remained the same indicating that removed variables may not be good value add to the fitness of the model\n",
    "- mnth_Feb has high p value > 0.05\n",
    "\n",
    "let's remove mnth_Feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove atemp which has very high p value and high VIF\n",
    "# Remove holiday as it has high p value\n",
    "# Remove mnth_Feb as it has high p value \n",
    "cols_to_be_removed = ['atemp','holiday','mnth_Feb']\n",
    "X_train_rfe_m = X_train_rfe.drop(cols_to_be_removed,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(add_constant(X_train_rfe_m),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_vif(X_train_rfe_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations:\n",
    "- Adjusted R square has remained the same indicating that removed variables may not be good value add to the fitness of the model\n",
    "- hum has high vif\n",
    "\n",
    "let's remove hum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove atemp which has very high p value and high VIF\n",
    "# Remove holiday as it has high p value\n",
    "# Remove mnth_Feb as it has high p value \n",
    "# Remove hum as it has high VIF\n",
    "cols_to_be_removed = ['atemp','holiday','mnth_Feb','hum']\n",
    "X_train_rfe_m = X_train_rfe.drop(cols_to_be_removed,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(add_constant(X_train_rfe_m),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_vif(X_train_rfe_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations:\n",
    "- Adjusted R square has approx remained the same indicating that removed variables may not be good value add to the fitness of the model\n",
    "- weekday_Mon has high p value\n",
    "\n",
    "let's remove weekday_Mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove atemp which has very high p value and high VIF\n",
    "# Remove holiday as it has high p value\n",
    "# Remove mnth_Feb as it has high p value \n",
    "# Remove hum as it has high VIF\n",
    "# Remove weekday_Mon as it has high p value \n",
    "cols_to_be_removed = ['atemp','holiday','mnth_Feb','hum','weekday_Mon']\n",
    "X_train_rfe_m = X_train_rfe.drop(cols_to_be_removed,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary, final_model = build_model(add_constant(X_train_rfe_m),y_train)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_vif(X_train_rfe_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations:\n",
    "- Adjusted R square has approx remained the same indicating that removed variables may not be good value add to the fitness of the model\n",
    "- Since all the variables p values are less than 0.05, no feature elimination required based on p value\n",
    "- Even though temp has slightly higher value of VIF, but removing temp will cause R square to drop by 5%. Since VIF is only slightly higher but temp being able to explain 5% more variance(Adjusted R square) in the data, let's keep temp and declare this as final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = final_model.predict(add_constant(X_train_rfe_m))\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the residuals to confirm the Linear Regression Assumptions\n",
    "res = y_train - y_train_pred\n",
    "fig = plt.figure()\n",
    "sns.distplot(res)\n",
    "fig.suptitle('Error Terms', fontsize = 20)  \n",
    "plt.xlabel('Errors', fontsize = 18) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions verified:\n",
    "- Residuals seems to have zero mean and follow normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.scatterplot(x=X_train_rfe_m['temp'],y=res)\n",
    "plt.subplot(1,2,2)\n",
    "sns.scatterplot(x=X_train_rfe_m['windspeed'],y=res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions verified:\n",
    "- Residuals doesn't seem to have any pattern and independent\n",
    "- Residuals seems to have constant variance most of the time except for some outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Predictions and Evaluations using the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the Scaling on test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the numerical columns other than categorical dummy cols\n",
    "num_vars = ['temp','atemp','hum','windspeed','cnt']\n",
    "df_test[num_vars] = scaler.transform(df_test[num_vars])\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the test set into X and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.pop('cnt')\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns which were removed during model building process\n",
    "X_test_final = X_test[X_train_rfe_m.columns] \n",
    "X_test_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = final_model.predict(add_constant(X_test_final))\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rsquare of model from the test set\n",
    "r_square_test = r2_score(y_test,y_test_pred)\n",
    "r_square_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- r_square of test set is just 3% less than that of training set. This implies model generalizes quite well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
